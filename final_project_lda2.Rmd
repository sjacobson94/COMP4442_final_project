---
title: "STAT 4442 Final Project"
author: "Wayne Yandell & Sawyer Jacobson"
date: "8/9/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```


# Read the data from the csv

```{r}
library(tidyverse)
library(tidytext)
library(stm)
library(knitr)
library(stringr)
library(magrittr)
library(stringi)
library(quanteda)
library(topicmodels)
# Read in the data from the csv
covid_texts <- read.csv("covid_2020.csv") %>%   
  tibble::as_tibble()                       


```

# Convert to tidytext to document-frequency-matrix to document-term-matrix

```{r}
covid_2020 <- covid_2020[c('cord_uid','abstract')] %>%
  group_by(cord_uid) %>%
  mutate(articleID = row_number()) %>%
  ungroup()

tidy_abstracts <- covid_2020 %>%
  unnest_tokens(word, abstract) %>%
  anti_join(stop_words)

tidy_abstracts %>%
  count(word, sort = TRUE) %>%
  filter(n > 8000) %>%
  mutate(word = reorder(word,n)) %>%
  ggplot(aes(word, n)) +
  geom_col() +
  xlab(NULL) +
  coord_flip()

tidy_abstracts <- tidy_abstracts %>%
  filter(!(word %in% c('covid','coronavirus', 'cov', 'patients', 'sars', 'disease','pandemic', 'health') | str_detect(word, pattern = "\\d+")))


tidy_abstracts
word_counts <- tidy_abstracts %>%
  count(cord_uid, word, sort = TRUE)

abstract_dfm <- word_counts %>%
  cast_dfm(cord_uid, word, n)

word_counts

abstract_dtm <- convert(abstract_dfm, to = "topicmodels")
```

# Determine the best number of latent topics

```{r}
library(ldatuning)
result <- FindTopicsNumber(
  abstract_dtm,
  topics = seq(from = 2, to = 15, by = 1),
  metrics = c("Griffiths2004", "CaoJuan2009", "Arun2010", "Deveaud2014"),
  method = "Gibbs",
  control = list(seed = 77),
  verbose = TRUE
)
FindTopicsNumber_plot(result)
```

# Use Latent Dirichlet Allocation and output topics with indicative tokens

```{r}
lda <- LDA(abstract_dtm, k = 13)
terms(lda, 10)

abstract_stm <- stm(abstract_dfm, K = 13, verbose = FALSE, init.type = "Spectral")
td_beta <- tidy(abstract_stm)

td_beta %>%
    group_by(topic) %>%
    top_n(10, beta) %>%
    ungroup() %>%
    mutate(topic = paste0("Topic ", topic),
           term = reorder_within(term, beta, topic)) %>%
    ggplot(aes(term, beta, fill = as.factor(topic))) +
    geom_col(alpha = 0.8, show.legend = FALSE) +
    facet_wrap(~ topic, scales = "free_y") +
    coord_flip() +
    scale_x_reordered() +
    labs(x = NULL, y = expression(beta),
         title = "Highest word probabilities for each topic",
         subtitle = "Different words are associated with different topics")

td_gamma <- tidy(abstract_stm, matrix = "gamma",                    
                 document_names = rownames(abstract_dfm))

ggplot(td_gamma, aes(gamma, fill = as.factor(topic))) +
  geom_histogram(alpha = 0.8, show.legend = FALSE) +
  facet_wrap(~ topic, ncol = 3) +
  labs(title = "Distribution of document probabilities for each topic",
       y = "Number of articles", x = expression(gamma))
```

